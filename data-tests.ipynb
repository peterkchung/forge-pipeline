{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetically-Created, Human-Evaluated Reasoning Dataset\n",
    "\n",
    "- CommonsenseQA, StrategyQA\n",
    "- Varitions on questions / tasks / queries\n",
    "- Human eval\n",
    "- Think step-by-step reasoning prompts\n",
    "- Huamn eval\n",
    "- Answers to query + reasoning\n",
    "- Human eval\n",
    "\n",
    "Aim for 1,000 starting sampleset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "from pprint import pprint\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 9741\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 1221\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "        num_rows: 1140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CommonsenseQA from TAU (Tel Aviv University)\n",
    "\n",
    "https://arxiv.org/abs/1811.00937\n",
    "\n",
    "\"\"\"\n",
    "dataset_id = 'tau/commonsense_qa'\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
      "    num_rows: 9741\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train']\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9741"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answerKey': 'A',\n",
      " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
      "             'text': ['loss of heat',\n",
      "                      'revenge',\n",
      "                      'expansion',\n",
      "                      'relaxation',\n",
      "                      'calm down']},\n",
      " 'id': 'b63b9809c203321d6659ddf8551894bf',\n",
      " 'question': \"James was cooling off two quickly.  He would die if he didn't \"\n",
      "             'find some way to stop what?',\n",
      " 'question_concept': 'cooling off'}\n"
     ]
    }
   ],
   "source": [
    "q_no = 13\n",
    "pprint(train_dataset[q_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Q: James was cooling off two quickly. He would die if he didn't find some \"\n",
      " 'way to stop what?\\n'\n",
      " '    Choices: loss of heat, revenge, expansion, relaxation, calm down\\n'\n",
      " \"    A: Let's think step by step.\")\n",
      "Response 1:  James is in aggressive surroundings and he's hot. He can regulate temperature if he's burning up, so the answer to our riddle is 'loss of heat'.\n",
      "Response 2:  There is a story regarding James and some men trying to kill him. He's in his apartment and he knows they need just in to kill him. So he threw off his blanket during winter to increase his heart rate to produce more heat to stay\n",
      "Response 3:  James set himself on fire \"quickly,\" so he needs to find a way to stop the fire. The first thing which comes to mind here is loss of heat. A burning object takes in heat from its surroundings and that's why James was\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "model_id = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "\n",
    "queries = random.sample(range(1, len(train_dataset) + 1), 1000)\n",
    "\n",
    "responses = []\n",
    "\n",
    "for q in queries:\n",
    "    query = train_dataset[q]['question'].replace('  ', ' ')\n",
    "    choices = train_dataset[q]['choices']['text']\n",
    "\n",
    "    client = InferenceClient(\n",
    "        model=model_id,\n",
    "        token=os.getenv('HUGGINGFACE_TOKEN'),\n",
    "    )\n",
    "\n",
    "    prompt = f\"Q: {query}\\n\\\n",
    "        Choices: {', '.join(choices)}\\n\\\n",
    "        A: Let's think step by step.\"\n",
    "    pprint(prompt)\n",
    "\n",
    "    seed = random.randint(0, 10000)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            output = client.text_generation(\n",
    "                prompt,\n",
    "                max_new_tokens=50,\n",
    "                do_sample=True,\n",
    "                seed=seed\n",
    "            )\n",
    "            break\n",
    "        except:\n",
    "            print(\"An interruption occurred. Retrying in 3 minutes.\")\n",
    "            time.sleep(180)  \n",
    "    \n",
    "    response = {\n",
    "        'id': train_dataset[q]['id'],\n",
    "        'response': output['generated_text']\n",
    "    }\n",
    "    responses.append(response)\n",
    "    time.sleep(random.uniform(1, 10))\n",
    "\n",
    "# Save responses to a JSON file\n",
    "with open('responses.json', 'w') as f:\n",
    "    json.dump(responses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
